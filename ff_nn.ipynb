{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import torch\n",
    "import sys\n",
    "import cvxpy as cp\n",
    "import tqdm\n",
    "import importlib\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self,input_size):\n",
    "        super(Net, self).__init__()\n",
    "        #input_size should be the length of the features vector, specified at the begining \n",
    "        self.fc1 = nn.Linear(input_size, 2**8)\n",
    "        self.fc2 = nn.Linear(2**8, 2**8)\n",
    "        self.fc3 = nn.Linear(2**8, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __len__(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __add__(self, other):\n",
    "        return ConcatDataset([self, other])\n",
    "\n",
    "class CryptoData(Dataset):\n",
    "    \n",
    "    def __init__(self, file_path,transform):\n",
    "        self.data = pd.read_csv(file_path)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # load image as ndarray type (Height * Width * Channels)\n",
    "        # be carefull for converting dtype to np.uint8 [Unsigned integer (0 to 255)]\n",
    "        # in this example, i don't use ToTensor() method of torchvision.transforms\n",
    "        # so you can convert numpy ndarray shape to tensor in PyTorch (H, W, C) --> (C, H, W)\n",
    "        image = self.data.iloc[index, 1:51]\n",
    "        image = np.array([image])\n",
    "        label = self.data.loc[index, 'label']\n",
    "        label = np.array([image])\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0          0           1           2         3          4  \\\n",
      "0           0  35.914223  340.111783  244.191304  1.745412  93.341758   \n",
      "1           1   1.550017   13.919287    0.000182 -0.000060   0.000081   \n",
      "2           2   0.028112    0.283912    0.000314  0.000403   0.034164   \n",
      "3           3   0.735473    6.987971    0.023240  0.035425   1.564482   \n",
      "4           4   0.785418    7.461572    0.025315  0.037810   1.743876   \n",
      "\n",
      "              5         6             7             8  ...           41  \\\n",
      "0 -2.694931e-07 -0.660855  6.313410e-03  9.161955e-08  ...  1955.011107   \n",
      "1 -4.859265e-09 -0.000003  9.368407e-09  1.002605e-09  ...     2.950600   \n",
      "2  2.537544e-08 -0.000005  3.713815e-06  2.054972e-08  ...     0.566343   \n",
      "3 -5.215645e-08 -0.000381  7.435807e-05  3.000300e-08  ...    57.357101   \n",
      "4  4.026456e-08 -0.000415  8.040126e-05 -5.799183e-08  ...    61.479207   \n",
      "\n",
      "           42          43           44           45          46            47  \\\n",
      "0  581.310317 -788.282830 -2446.841806 -2197.341725 -511.854005  32186.191727   \n",
      "1  -21.700914  -18.338161   -25.633476   -14.864837    7.697761     99.319204   \n",
      "2    0.235640    0.318668    -0.868028    -0.764955   -0.278572      7.528032   \n",
      "3   -1.602995    7.372162   -64.270871   -49.237098   32.565719    288.041732   \n",
      "4   -1.490380    5.159551   -69.120870   -52.861949   34.309609    311.053840   \n",
      "\n",
      "             48            49  label  \n",
      "0  13912.432357  1.016237e+06      0  \n",
      "1    110.960100  2.268857e+02      0  \n",
      "2      7.299410  1.714181e+02      0  \n",
      "3    114.192885  1.087261e+04      0  \n",
      "4    125.332719  1.165440e+04      0  \n",
      "\n",
      "[5 rows x 52 columns]\n"
     ]
    }
   ],
   "source": [
    "dataframe = pd.read_csv('/Users/linusbleistein/Documents/Cours ENS/Cours matheÃÅmatiques/Deep learning 2020-2021/data_project/processed_data.csv')\n",
    "print(dataframe.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe=dataframe.drop(dataframe.columns[0],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = dataframe.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = torch.Tensor(dataframe)\n",
    "dataframe = torch.utils.data.TensorDataset(dataframe[:,0:-1],dataframe[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataloader = torch.utils.data.DataLoader(dataframe,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 0.682\n",
      "[1,  4000] loss: 0.617\n",
      "[1,  6000] loss: 0.605\n",
      "[1,  8000] loss: 0.597\n",
      "[1, 10000] loss: 0.589\n",
      "[1, 12000] loss: 0.580\n",
      "[1, 14000] loss: 0.573\n",
      "[1, 16000] loss: 0.568\n",
      "[1, 18000] loss: 0.560\n",
      "[1, 20000] loss: 0.552\n",
      "[1, 22000] loss: 0.545\n",
      "[1, 24000] loss: 0.537\n",
      "[1, 26000] loss: 0.531\n",
      "[1, 28000] loss: 0.524\n",
      "[1, 30000] loss: 0.517\n",
      "[1, 32000] loss: 0.510\n",
      "[1, 34000] loss: 0.505\n",
      "[1, 36000] loss: 0.498\n",
      "[1, 38000] loss: 0.490\n",
      "[1, 40000] loss: 0.483\n",
      "[1, 42000] loss: 0.477\n",
      "[1, 44000] loss: 0.471\n",
      "[1, 46000] loss: 0.464\n",
      "[1, 48000] loss: 0.458\n",
      "[1, 50000] loss: 0.452\n",
      "[1, 52000] loss: 0.446\n",
      "[1, 54000] loss: 0.441\n",
      "[1, 56000] loss: 0.434\n",
      "[1, 58000] loss: 0.429\n",
      "[1, 60000] loss: 0.424\n",
      "[1, 62000] loss: 0.419\n",
      "[1, 64000] loss: 0.414\n",
      "[1, 66000] loss: 0.410\n",
      "[1, 68000] loss: 0.405\n",
      "[1, 70000] loss: 0.401\n",
      "[2,  2000] loss: 0.393\n",
      "[2,  4000] loss: 0.389\n",
      "[2,  6000] loss: 0.385\n",
      "[2,  8000] loss: 0.382\n",
      "[2, 10000] loss: 0.379\n",
      "[2, 12000] loss: 0.376\n",
      "[2, 14000] loss: 0.374\n",
      "[2, 16000] loss: 0.371\n",
      "[2, 18000] loss: 0.368\n",
      "[2, 20000] loss: 0.366\n",
      "[2, 22000] loss: 0.364\n",
      "[2, 24000] loss: 0.361\n",
      "[2, 26000] loss: 0.360\n",
      "[2, 28000] loss: 0.358\n",
      "[2, 30000] loss: 0.356\n",
      "[2, 32000] loss: 0.354\n",
      "[2, 34000] loss: 0.353\n",
      "[2, 36000] loss: 0.351\n",
      "[2, 38000] loss: 0.349\n",
      "[2, 40000] loss: 0.348\n",
      "[2, 42000] loss: 0.347\n",
      "[2, 44000] loss: 0.346\n",
      "[2, 46000] loss: 0.344\n",
      "[2, 48000] loss: 0.343\n",
      "[2, 50000] loss: 0.342\n",
      "[2, 52000] loss: 0.341\n",
      "[2, 54000] loss: 0.340\n",
      "[2, 56000] loss: 0.339\n",
      "[2, 58000] loss: 0.338\n",
      "[2, 60000] loss: 0.338\n",
      "[2, 62000] loss: 0.337\n",
      "[2, 64000] loss: 0.336\n",
      "[2, 66000] loss: 0.335\n",
      "[2, 68000] loss: 0.335\n",
      "[2, 70000] loss: 0.334\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "net=Net(input_size=50)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.00001, momentum=0.9)\n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(my_dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        labels = labels.long()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9544, 0.0450], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(dataframe[300][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
