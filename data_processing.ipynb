{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "solid-township",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "brown-journalist",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import glob \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import os \n",
    "import sklearn\n",
    "import scipy.sparse\n",
    "from scipy.sparse import csr_matrix\n",
    "from pandas.api.types import CategoricalDtype\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "constant-crisis",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/julesbaudet/Documents/0. Cours/ENS/Deep Learning DIY/Projet final/ens_data\"\n",
    "# path = \"/Users/linusbleistein/Documents/Cours ENS/Cours math√©matiques/Deep learning 2020-2021/data_project\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "lesbian-eleven",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(path,\"clean_brave_data.csv\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "allied-partnership",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = 'Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-resistance",
   "metadata": {},
   "source": [
    "## Transaction History Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "corresponding-manitoba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the known exchange list \n",
    "exch_labels = pd.read_csv(os.path.join(path, \"exchanges_encoded.csv\"), \n",
    "                          delimiter=';', names  = ['address','label']).set_index('address')\n",
    "\n",
    "labels = exch_labels.to_dict()['label']\n",
    "\n",
    "labels2int = dict(zip(labels.values(),[i for i in range(len(labels))])) # keys = addresses, values = name of the exchange\n",
    "address2int = {k:labels2int[labels[k]] for k in labels.keys()}\n",
    "\n",
    "known_addresses = list(labels.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "complete-continuity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop transactions of addresses who only made 1 transaction \n",
    "a = (df.groupby('from_address').count() + df.groupby('to_address').count())['value']\n",
    "idx = a[a<3][~a[a<3].index.isin(known_addresses)].index\n",
    "df = df.drop(df.loc[df['from_address'].isin(idx)|df['from_address'].isin(idx)].index).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complicated-evans",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum([len(v)!=42 for v in df['from_address'].values]) # check that all addresses have same format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-settlement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['transaction_id'] = df['from_address']+df['to_address']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exclusive-fleece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['transaction_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anonymous-contest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.sort_values('unix_block_timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-bubble",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_size = df['transaction_id'].nunique()\n",
    "# word2vec = Word2Vec(vocab_size=vocab_size, embedding_size=300)\n",
    "# sgns = SGNS(embedding=word2vec, vocab_size=vocab_size, n_negs=20)\n",
    "# optim = Adam(sgns.parameters())\n",
    "# for batch, (iword, owords) in enumerate(dataloader):\n",
    "#     loss = sgns(iword, owords)\n",
    "#     optim.zero_grad()\n",
    "#     loss.backward()\n",
    "#     optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dimensional-differential",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we create an one-hot encoding of all transactions ranked by chronological order\n",
    "hot_encoding =  csr_matrix((np.ones(df.shape[0]),(df.index.values, df.index.values)), shape=(df.shape[0], df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "oriental-regression",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = '0x88e2efac3d2ef957fcd82ec201a506871ad06204'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "distant-roberts",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.unique(np.hstack((df.from_address.values, df['to_address'].values))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fundamental-calendar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we create a dictionnary address: [transaction nbrs] where the transaction nbrs involve the address\n",
    "all_addresses  = np.hstack((df.from_address.unique(),\n",
    "                            df.loc[~df['to_address'].isin(df['from_address'])].to_address.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "alpine-programmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_add = df.loc[~df['to_address'].isin(df['from_address'])].copy()\n",
    "to_add = to_add.rename(columns={'to_address':'from_address','from_address':'to_address'})\n",
    "to_add['value'] = 0\n",
    "df2 = pd.concat((df,to_add))\n",
    "\n",
    "categories = CategoricalDtype(sorted(df2.from_address.unique()), ordered=True) # will have all nodes! use it for all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "standard-shareware",
   "metadata": {},
   "outputs": [],
   "source": [
    "from_c = df.from_address.astype(categories).cat.codes # .unique().shape\n",
    "to_c = df.loc[df.from_address != df.to_address].to_address.astype(categories).cat.codes\n",
    "\n",
    "vocab = pd.DataFrame(np.hstack((from_c,to_c)), columns=['address'])\n",
    "vocab['transactions'] = np.hstack((from_c.index, to_c.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "sharing-headline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.6 s, sys: 182 ms, total: 17.8 s\n",
      "Wall time: 18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vocab = vocab.groupby('address')['transactions'].apply(list).reset_index(name='transactions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "champion-brief",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>transactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[[30449, 34453, 956587, 1348259, 1713041, 1926...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[[485438, 1486175]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[[457529]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[[1063476, 1234990]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[[513642, 513654]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   address                                       transactions\n",
       "0        0  [[30449, 34453, 956587, 1348259, 1713041, 1926...\n",
       "1        1                                [[485438, 1486175]]\n",
       "2        2                                         [[457529]]\n",
       "3        3                               [[1063476, 1234990]]\n",
       "4        4                                 [[513642, 513654]]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ARE THEY IN ORDER? CHECK! \n",
    "vocab.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "another-mayor",
   "metadata": {},
   "source": [
    "## Transaction stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decreased-season",
   "metadata": {},
   "source": [
    "## Creating a data  embedding (OLD)\n",
    "\n",
    "To be able to learn a classification of nodes on our graph, we need to transform the data on nodes to be able to express some of the information contained in graph form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-nursery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix of adjacency with line data relative to sent transactions only \n",
    "# %%time\n",
    "# from_c = CategoricalDtype(sorted(df.from_address.unique()), ordered=True)\n",
    "# to_c = CategoricalDtype(sorted(df.to_address.unique()), ordered=True)\n",
    "# \n",
    "# row = df.from_address.astype(from_c).cat.codes\n",
    "# col = df.to_address.astype(to_c).cat.codes\n",
    "# sparse = csr_matrix((df[\"value\"], (row, col)), \\\n",
    "#                            shape=(from_c.categories.size, to_c.categories.size))\n",
    "# print(sparse.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "successful-block",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-68-4069e6302457>, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-68-4069e6302457>\"\u001b[0;36m, line \u001b[0;32m18\u001b[0m\n\u001b[0;31m    sp2 = csr_matrix((-df['value'],(col, row)), shape=(categories.categories.size, categories.categories.size))\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# matrix of adjacency with line data relative to sent and received transactions \n",
    "%%time\n",
    "# first we add addresses that only received but not sent to first column \n",
    "to_add = df.loc[~df['to_address'].isin(df['from_address'])].copy()\n",
    "to_add = to_add.rename(columns={'to_address':'from_address','from_address':'to_address'})\n",
    "to_add['value'] = 0\n",
    "\n",
    "df = pd.concat((df,to_add))\n",
    "\n",
    "categories = CategoricalDtype(sorted(df.from_address.unique()), ordered=True) # will have all nodes! use it for all \n",
    "row = df.to_address.astype(categories).cat.codes\n",
    "col = df.from_address.astype(categories).cat.codes\n",
    "\n",
    "# sparse matrix for values sent \n",
    "sp = csr_matrix((df['value'],(row, col)), shape=(categories.categories.size, categories.categories.size)\n",
    "                \n",
    "# sparse matrix for values received \n",
    "sp2 = csr_matrix((-df['value'],(col, row)), shape=(categories.categories.size, categories.categories.size))\n",
    "                \n",
    "# our data \n",
    "X = scipy.sparse.hstack((sp,sp2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-argument",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gorgeous-livestock",
   "metadata": {},
   "source": [
    "##  Dimension Reduction   \n",
    "\n",
    "Our data has particularly high dimension. We use truncated SVD to reduce our data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-revelation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-support",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tsvd = TruncatedSVD(n_components=65, random_state=42)\n",
    "out = tsvd.fit_transform(X)\n",
    "print(f'our data has shape {out.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plain-criminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsvd_var_ratios = tsvd.explained_variance_ratio_\n",
    "print(tsvd_var_ratios.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "three-channels",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken on https://chrisalbon.com/machine_learning/feature_engineering/select_best_number_of_components_in_tsvd/\n",
    "def select_n_components(var_ratio, goal_var: float) -> int:\n",
    "    total_variance = 0.0\n",
    "    n_components = 0\n",
    "    for explained_variance in var_ratio:\n",
    "        total_variance += explained_variance\n",
    "        n_components += 1\n",
    "        if total_variance >= goal_var:\n",
    "            break\n",
    "    return n_components\n",
    "\n",
    "var_goal =  0.99\n",
    "print(f'to keep {var_goal*100}% of variance, one should keep {select_n_components(tsvd_var_ratios,var_goal)} components')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pharmaceutical-brush",
   "metadata": {},
   "source": [
    "##  Adding the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-oakland",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.vectorize(address2int.get)(np.array(categories.categories))\n",
    "labels = np.nan_to_num(labels.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "returning-contamination",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-episode",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(out)\n",
    "# data['label'] = np.isin(np.array(sorted(df.from_address.unique())),known_addresses).astype(int)\n",
    "data['label'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blessed-source",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(os.path.join(path,\"processed_data.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "third-brisbane",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yellow-capitol",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elect-machinery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Debugging example\n",
    "# a = pd.DataFrame({\"col\": [15, 32, 3, 8], \"col2\":[26,3,17,20], \"value\":[1,1,1,1]})\n",
    "# \n",
    "# # add this to the sparse matrix \n",
    "# add = a.loc[~a['col2'].isin(a['col'])].copy()\n",
    "# add = add.rename(columns={'col':'col2','col2':'col'})\n",
    "# #add['value'] = 0 # -to_add['value']\n",
    "# \n",
    "# a = pd.concat((a,add))\n",
    "# \n",
    "# categories = CategoricalDtype(sorted(a.col.unique()), ordered=True) # will have all nodes! use it for all \n",
    "# row = a.col.astype(categories).cat.codes\n",
    "# col = a.col2.astype(categories).cat.codes\n",
    "# sp = csr_matrix((a['value'],(row, col)), shape=(categories.categories.size, categories.categories.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-algebra",
   "metadata": {},
   "source": [
    "## Handling time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "least-doctrine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "narrative-boards",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['day'] = df['unix_block_timestamp']//(60*60*24)  # euclidean division to get the day number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "specified-documentary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # tests\n",
    "# df['unix_block_timestamp'].max()//(60*60*24)\n",
    "# datetime.utcfromtimestamp(df['unix_block_timestamp'].max())\n",
    "# datetime.utcfromtimestamp(df['unix_block_timestamp'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "mathematical-gross",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby(by='day').count().plot(y='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "short-rally",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  plt.subplots(figsize = (20,7))\n",
    "#  test = df.groupby(['day']).nunique()['from_address']\n",
    "#  test.hist(bins = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acceptable-bronze",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "developed-petroleum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.subplots(figsize = (20,7))\n",
    "# df.groupby(by='day').count()['value'].hist(bins = 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
