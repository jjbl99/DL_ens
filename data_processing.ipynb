{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "solid-township",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "brown-journalist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/julesbaudet/Documents/0. Cours/ENS/Deep Learning DIY/Projet final/DL_ens'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import glob \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import os \n",
    "import sklearn\n",
    "import scipy.sparse\n",
    "from scipy.sparse import csr_matrix\n",
    "from pandas.api.types import CategoricalDtype\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "constant-crisis",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/julesbaudet/Documents/0. Cours/ENS/Deep Learning DIY/Projet final/ens_data\"\n",
    "# path = \"/Users/linusbleistein/Documents/Cours ENS/Cours math√©matiques/Deep learning 2020-2021/data_project\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "lesbian-eleven",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2695566, 9)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(path,\"clean_brave_data.csv\")).sort_values('unix_block_timestamp')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "sapphire-possible",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = 'Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-vampire",
   "metadata": {},
   "source": [
    "## Transaction History Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "handled-funds",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the known exchange list \n",
    "\n",
    "exch_labels = pd.read_csv(os.path.join(path, \"exchanges_encoded.csv\"), \n",
    "                          delimiter=';', names  = ['address','label']).set_index('address')\n",
    "\n",
    "labels = exch_labels.to_dict()['label']\n",
    "\n",
    "labels2int = dict(zip(labels.values(),[i for i in range(len(labels))])) # keys = addresses, values = name of the exchange\n",
    "address2int = {k:labels2int[labels[k]] for k in labels.keys()}\n",
    "\n",
    "known_addresses = list(labels.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "confirmed-brand",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop transactions of addresses who only made 1 transaction \n",
    "\n",
    "a = (df.groupby('from_address').count() + df.groupby('to_address').count())['value']\n",
    "idx = a[a<3][~a[a<3].index.isin(known_addresses)].index\n",
    "df = df.drop(df.loc[df['from_address'].isin(idx)|df['from_address'].isin(idx)].index).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ethical-sunday",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['transaction_id'] = df['from_address'] + df['to_address']\n",
    "df = df.drop(columns = ['labels_send', 'labels_receive'])\n",
    "# np.savetxt('data/trainset.txt',df['transaction_id'].values, fmt = '%s', delimiter =' ', newline =' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "effective-maple",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.5 s, sys: 1.47 s, total: 34.9 s\n",
      "Wall time: 44.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# add information on transactions\n",
    "df['tfrequency'] = df.groupby('transaction_id')['value'].transform('count') \n",
    "# df['avg_value'] = df.groupby('transaction_id')['value'].transform('mean') \n",
    "df['std_value'] = df.groupby('transaction_id')['value'].transform('std') \n",
    "df['median_value'] = df.groupby('transaction_id')['value'].transform('median') \n",
    "df['lifetime'] = df.groupby('transaction_id')['unix_block_timestamp'].transform('max') - df.groupby('transaction_id')['unix_block_timestamp'].transform('min')\n",
    "df['lifetime'] = df['lifetime']/df['lifetime'].max()\n",
    "df['first_date'] = df.groupby('transaction_id')['unix_block_timestamp'].transform('min')\n",
    "df['unix_block_timestamp'] = (df['unix_block_timestamp']-df['unix_block_timestamp'].min())/(df['unix_block_timestamp'].max()-df['unix_block_timestamp'].min())\n",
    "\n",
    "\n",
    "data = df.groupby('transaction_id').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "specific-smoke",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'value', 'unix_block_timestamp', 'send_is_id', 'receive_is_id',\n",
       "       'tfrequency', 'std_value', 'median_value', 'lifetime', 'first_date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "reasonable-theme",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# \n",
    "# source_file = open('data/final_output.txt', 'r')\n",
    "# source_file.readline()\n",
    "# # this will truncate the file, so need to use a different file name:\n",
    "# target_file = open('final_output2.txt.new', 'w')\n",
    "# \n",
    "# shutil.copyfileobj(source_file, target_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "middle-boost",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = pd.read_csv('data/model.txt', skiprows=1, sep=' ', header = None, index_col = 0)\n",
    "\n",
    "# Comment that line when you have full embedding \n",
    "#data = data.loc[data.index.isin(emb.index)] \n",
    "#emb = emb.loc[emb.index.isin(data.index)] \n",
    "#############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "front-arabic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(945377, 150)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "large-grenada",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_data = pd.concat((emb,data),axis=1)\n",
    "\n",
    "trans_data[['from_address','to_address']] = trans_data.index.str.extract('(.{42,42})' * 2).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "geological-somewhere",
   "metadata": {},
   "outputs": [],
   "source": [
    "dta1 = trans_data.sort_values('from_address').reset_index().rename(columns = {'from_address':'address', 'send_is_id':'label'})\n",
    "dta1 = dta1.drop(columns = ['to_address','receive_is_id'])\n",
    "dta2 = trans_data.loc[trans_data['from_address'] != trans_data['to_address']].sort_values('to_address').reset_index()\n",
    "dta2 = dta2.rename(columns = {'to_address':'address', 'receive_is_id':'label'}).drop(columns = ['from_address','send_is_id'])\n",
    "\n",
    "##########\n",
    "# dta2 = dta1.copy() # TO DELETE LATER \n",
    "##########\n",
    "\n",
    "dta2['value'] = - dta2['value']\n",
    "dta2['median_value'] = - dta2['median_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "competent-surfing",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pd.concat((dta1,dta2)).sort_values(['address','first_date']).drop(columns=['index','first_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "second-record",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "      <th>value</th>\n",
       "      <th>unix_block_timestamp</th>\n",
       "      <th>label</th>\n",
       "      <th>tfrequency</th>\n",
       "      <th>std_value</th>\n",
       "      <th>median_value</th>\n",
       "      <th>lifetime</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x3e6288bc299dac35d293949e08faae61547d297d0x00...</td>\n",
       "      <td>0.002860</td>\n",
       "      <td>0.002553</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>-0.002919</td>\n",
       "      <td>-0.000901</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>-0.000329</td>\n",
       "      <td>-0.000971</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002145</td>\n",
       "      <td>-0.000914</td>\n",
       "      <td>-475350.000000</td>\n",
       "      <td>0.026648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-475350.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0x0000000000000000000000000000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0xb14ce8465a0a2ec321c7da6c9313103dff762ef00x00...</td>\n",
       "      <td>-0.001349</td>\n",
       "      <td>0.001012</td>\n",
       "      <td>-0.002908</td>\n",
       "      <td>0.001011</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000885</td>\n",
       "      <td>-0.000613</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001322</td>\n",
       "      <td>-0.000831</td>\n",
       "      <td>-3381.990227</td>\n",
       "      <td>0.033807</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3381.990227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0x0000000000000000000000000000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0xf7c8b97a2f8e6df7e0126e6fa953e257b7de9dc20x00...</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>-0.001626</td>\n",
       "      <td>0.001550</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.001593</td>\n",
       "      <td>-0.003225</td>\n",
       "      <td>-0.001264</td>\n",
       "      <td>-0.000218</td>\n",
       "      <td>-0.002452</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001393</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>0.628644</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0x0000000000000000000000000000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x340d693ed55d7ba167d184ea76ea2fd092a35bdc0x00...</td>\n",
       "      <td>0.003111</td>\n",
       "      <td>0.001909</td>\n",
       "      <td>0.003098</td>\n",
       "      <td>-0.003031</td>\n",
       "      <td>-0.000591</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>-0.002775</td>\n",
       "      <td>-0.002273</td>\n",
       "      <td>-0.001554</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000899</td>\n",
       "      <td>-0.000604</td>\n",
       "      <td>-12.387875</td>\n",
       "      <td>0.849646</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.342678</td>\n",
       "      <td>-12.387875</td>\n",
       "      <td>0.120074</td>\n",
       "      <td>0x0000000000000000000000000000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0xd8322486c4e13ad800bde0174b7397bb86189ea20x00...</td>\n",
       "      <td>-0.000961</td>\n",
       "      <td>-0.001208</td>\n",
       "      <td>-0.001371</td>\n",
       "      <td>0.001580</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>-0.002572</td>\n",
       "      <td>0.002252</td>\n",
       "      <td>-0.002978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002091</td>\n",
       "      <td>0.002941</td>\n",
       "      <td>-2.016700</td>\n",
       "      <td>0.874982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.016700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0x0000000000000000000000000000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944426</th>\n",
       "      <td>0x35f4db7d3bc121562f99aab530b0f95330ca70710xff...</td>\n",
       "      <td>0.002740</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>-0.000125</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>-0.000385</td>\n",
       "      <td>0.001274</td>\n",
       "      <td>0.002561</td>\n",
       "      <td>0.003069</td>\n",
       "      <td>-0.002111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000742</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>-32.404034</td>\n",
       "      <td>0.594525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-32.404034</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0xffffc583d80cf66aa156eaee3bf5f185890c02de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944427</th>\n",
       "      <td>0x340d693ed55d7ba167d184ea76ea2fd092a35bdc0xff...</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>0.001894</td>\n",
       "      <td>-0.001994</td>\n",
       "      <td>0.001631</td>\n",
       "      <td>-0.000927</td>\n",
       "      <td>-0.003018</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>-0.002421</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002164</td>\n",
       "      <td>-0.000229</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>0.742843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0xffffd78093141d7e2eb923b76053effcec377fbf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944428</th>\n",
       "      <td>0xe93381fb4c4f14bda253907b18fad305d799241a0xff...</td>\n",
       "      <td>-0.002737</td>\n",
       "      <td>-0.002992</td>\n",
       "      <td>-0.001259</td>\n",
       "      <td>0.002574</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>-0.001486</td>\n",
       "      <td>0.002444</td>\n",
       "      <td>-0.001596</td>\n",
       "      <td>-0.000914</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002560</td>\n",
       "      <td>-0.002364</td>\n",
       "      <td>-200.000000</td>\n",
       "      <td>0.524202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-200.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0xffffe661474073010cb7ab1f8af7b4505af6df5c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944429</th>\n",
       "      <td>0x794a8a2a9e7e360afd5290119c775ffa6b1af7c00xff...</td>\n",
       "      <td>-0.002909</td>\n",
       "      <td>-0.003191</td>\n",
       "      <td>-0.002699</td>\n",
       "      <td>-0.000057</td>\n",
       "      <td>0.002525</td>\n",
       "      <td>-0.001665</td>\n",
       "      <td>0.001021</td>\n",
       "      <td>0.002712</td>\n",
       "      <td>-0.001537</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001811</td>\n",
       "      <td>0.001249</td>\n",
       "      <td>-224.906038</td>\n",
       "      <td>0.880727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-224.906038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0xfffffe85ddb377d1a616cf2c43ae5556ad3987e8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944430</th>\n",
       "      <td>0x9ef773bd58575e295e6c51b972a3999a9af715590xff...</td>\n",
       "      <td>-0.003190</td>\n",
       "      <td>0.002298</td>\n",
       "      <td>-0.001834</td>\n",
       "      <td>0.003330</td>\n",
       "      <td>-0.002263</td>\n",
       "      <td>-0.003297</td>\n",
       "      <td>-0.000324</td>\n",
       "      <td>0.003289</td>\n",
       "      <td>-0.002620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002743</td>\n",
       "      <td>-0.000293</td>\n",
       "      <td>-30.904736</td>\n",
       "      <td>0.709636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-30.904736</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0xffffffff44ccc4d8057b06f60da10fc9c9420d2e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1889808 rows √ó 159 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  level_0         1         2  \\\n",
       "0       0x3e6288bc299dac35d293949e08faae61547d297d0x00...  0.002860  0.002553   \n",
       "5       0xb14ce8465a0a2ec321c7da6c9313103dff762ef00x00... -0.001349  0.001012   \n",
       "4       0xf7c8b97a2f8e6df7e0126e6fa953e257b7de9dc20x00... -0.000052 -0.001626   \n",
       "2       0x340d693ed55d7ba167d184ea76ea2fd092a35bdc0x00...  0.003111  0.001909   \n",
       "3       0xd8322486c4e13ad800bde0174b7397bb86189ea20x00... -0.000961 -0.001208   \n",
       "...                                                   ...       ...       ...   \n",
       "944426  0x35f4db7d3bc121562f99aab530b0f95330ca70710xff...  0.002740  0.000504   \n",
       "944427  0x340d693ed55d7ba167d184ea76ea2fd092a35bdc0xff...  0.000377  0.001894   \n",
       "944428  0xe93381fb4c4f14bda253907b18fad305d799241a0xff... -0.002737 -0.002992   \n",
       "944429  0x794a8a2a9e7e360afd5290119c775ffa6b1af7c00xff... -0.002909 -0.003191   \n",
       "944430  0x9ef773bd58575e295e6c51b972a3999a9af715590xff... -0.003190  0.002298   \n",
       "\n",
       "               3         4         5         6         7         8         9  \\\n",
       "0       0.001282  0.000694 -0.002919 -0.000901  0.000579 -0.000329 -0.000971   \n",
       "5      -0.002908  0.001011  0.000784  0.001800  0.000218  0.000885 -0.000613   \n",
       "4       0.001550  0.000116  0.001593 -0.003225 -0.001264 -0.000218 -0.002452   \n",
       "2       0.003098 -0.003031 -0.000591 -0.000034 -0.002775 -0.002273 -0.001554   \n",
       "3      -0.001371  0.001580  0.000663  0.000467 -0.002572  0.002252 -0.002978   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "944426 -0.000125  0.000434 -0.000385  0.001274  0.002561  0.003069 -0.002111   \n",
       "944427 -0.001994  0.001631 -0.000927 -0.003018  0.002701 -0.002421  0.000330   \n",
       "944428 -0.001259  0.002574  0.000814 -0.001486  0.002444 -0.001596 -0.000914   \n",
       "944429 -0.002699 -0.000057  0.002525 -0.001665  0.001021  0.002712 -0.001537   \n",
       "944430 -0.001834  0.003330 -0.002263 -0.003297 -0.000324  0.003289 -0.002620   \n",
       "\n",
       "        ...       149       150          value  unix_block_timestamp  label  \\\n",
       "0       ...  0.002145 -0.000914 -475350.000000              0.026648    0.0   \n",
       "5       ...  0.001322 -0.000831   -3381.990227              0.033807    0.0   \n",
       "4       ...  0.001393  0.000345      -4.000000              0.628644    0.0   \n",
       "2       ...  0.000899 -0.000604     -12.387875              0.849646    0.0   \n",
       "3       ...  0.002091  0.002941      -2.016700              0.874982    0.0   \n",
       "...     ...       ...       ...            ...                   ...    ...   \n",
       "944426  ...  0.000742  0.000038     -32.404034              0.594525    0.0   \n",
       "944427  ... -0.002164 -0.000229     -50.000000              0.742843    0.0   \n",
       "944428  ... -0.002560 -0.002364    -200.000000              0.524202    0.0   \n",
       "944429  ... -0.001811  0.001249    -224.906038              0.880727    0.0   \n",
       "944430  ...  0.002743 -0.000293     -30.904736              0.709636    0.0   \n",
       "\n",
       "        tfrequency  std_value   median_value  lifetime  \\\n",
       "0              1.0        NaN -475350.000000  0.000000   \n",
       "5              1.0        NaN   -3381.990227  0.000000   \n",
       "4              1.0        NaN      -4.000000  0.000000   \n",
       "2              2.0  17.342678     -12.387875  0.120074   \n",
       "3              1.0        NaN      -2.016700  0.000000   \n",
       "...            ...        ...            ...       ...   \n",
       "944426         1.0        NaN     -32.404034  0.000000   \n",
       "944427         1.0        NaN     -50.000000  0.000000   \n",
       "944428         1.0        NaN    -200.000000  0.000000   \n",
       "944429         1.0        NaN    -224.906038  0.000000   \n",
       "944430         1.0        NaN     -30.904736  0.000000   \n",
       "\n",
       "                                           address  \n",
       "0       0x0000000000000000000000000000000000000000  \n",
       "5       0x0000000000000000000000000000000000000000  \n",
       "4       0x0000000000000000000000000000000000000000  \n",
       "2       0x0000000000000000000000000000000000000000  \n",
       "3       0x0000000000000000000000000000000000000000  \n",
       "...                                            ...  \n",
       "944426  0xffffc583d80cf66aa156eaee3bf5f185890c02de  \n",
       "944427  0xffffd78093141d7e2eb923b76053effcec377fbf  \n",
       "944428  0xffffe661474073010cb7ab1f8af7b4505af6df5c  \n",
       "944429  0xfffffe85ddb377d1a616cf2c43ae5556ad3987e8  \n",
       "944430  0xffffffff44ccc4d8057b06f60da10fc9c9420d2e  \n",
       "\n",
       "[1889808 rows x 159 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "short-scholar",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = final_data.rename(columns={'level_0':'address_id'})\n",
    "\n",
    "# MAYBE REINDEX???? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "motivated-surrey",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = final_data.groupby('address').mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "divine-laser",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.to_csv(os.path.join(path,\"grouped_data_final.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-transfer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### fake dataset for debugging\n",
    "emb2 = pd.read_csv('data/model_test.txt', sep=' ', header =None, index_col = 0).reset_index()\n",
    "trans_data2 = data.iloc[:emb2.shape[0]].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "talented-undergraduate",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb2[trans_data2.columns] = trans_data2\n",
    "trans_data = emb2.rename(columns={0:'address_id'})\n",
    "trans_data[['from_address','to_address']] = trans_data.address_id.str.extract('(.{42,42})' * 2).values\n",
    "dta1 = trans_data.sort_values('from_address').reset_index().rename(columns = {'from_address':'address', 'send_is_id':'label'})\n",
    "dta1 = dta1.drop(columns = ['to_address','receive_is_id'])\n",
    "dta2 = trans_data.loc[trans_data['from_address'] != trans_data['to_address']].sort_values('to_address').reset_index()\n",
    "dta2 = dta2.rename(columns = {'to_address':'address', 'receive_is_id':'label'}).drop(columns = ['from_address','send_is_id'])\n",
    "\n",
    "##########\n",
    "# dta2 = dta1.copy() # TO DELETE LATER \n",
    "##########\n",
    "\n",
    "dta2['value'] = - dta2['value']\n",
    "dta2['median_value'] = - dta2['median_value']\n",
    "final_data = pd.concat((dta1,dta2)).sort_values(['address','first_date']).drop(columns=['index','first_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compatible-florence",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data['label'] = np.random.choice(2 ,p=[0.9,0.1], size = 1307) \n",
    "final_data = final_data.drop(columns='level_0')\n",
    "final_data.to_csv(os.path.join(path,\"test_data.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vanilla-paris",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "separated-growth",
   "metadata": {},
   "source": [
    "# Old tentatives (do not run these cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mental-phenomenon",
   "metadata": {},
   "source": [
    "##  Adding the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-triple",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.vectorize(address2int.get)(np.array(categories.categories))\n",
    "labels = np.nan_to_num(labels.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scenic-manor",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-contribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(out)\n",
    "# data['label'] = np.isin(np.array(sorted(df.from_address.unique())),known_addresses).astype(int)\n",
    "data['label'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funky-equality",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(os.path.join(path,\"processed_data.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legendary-identification",
   "metadata": {},
   "source": [
    "## Manual embedding (Old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-basin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we create a dictionnary address: [transaction nbrs] where the transaction nbrs involve the address\n",
    "all_addresses  = np.hstack((df.from_address.unique(),\n",
    "                            df.loc[~df['to_address'].isin(df['from_address'])].to_address.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revised-output",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_add = df.loc[~df['to_address'].isin(df['from_address'])].copy()\n",
    "to_add = to_add.rename(columns={'to_address':'from_address','from_address':'to_address'})\n",
    "to_add['value'] = 0\n",
    "df2 = pd.concat((df,to_add))\n",
    "\n",
    "categories = CategoricalDtype(sorted(df2.from_address.unique()), ordered=True) # will have all nodes! use it for all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "national-eligibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "from_c = df.from_address.astype(categories).cat.codes # .unique().shape\n",
    "to_c = df.loc[df.from_address != df.to_address].to_address.astype(categories).cat.codes\n",
    "\n",
    "vocab = pd.DataFrame(np.hstack((from_c,to_c)), columns=['address'])\n",
    "vocab['transactions'] = np.hstack((from_c.index, to_c.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "therapeutic-milwaukee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "vocab = vocab.groupby('address')['transactions'].apply(list).reset_index(name='transactions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustained-jungle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARE THEY IN ORDER? CHECK! \n",
    "vocab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-management",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# %run word2vec/train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepared-administrator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum([len(v)!=42 for v in df['from_address'].values]) # check that all addresses have same format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forward-navigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['transaction_id'] = df['from_address']+df['to_address']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wooden-musical",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['transaction_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endangered-hunter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.sort_values('unix_block_timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-realtor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_size = df['transaction_id'].nunique()\n",
    "# word2vec = Word2Vec(vocab_size=vocab_size, embedding_size=300)\n",
    "# sgns = SGNS(embedding=word2vec, vocab_size=vocab_size, n_negs=20)\n",
    "# optim = Adam(sgns.parameters())\n",
    "# for batch, (iword, owords) in enumerate(dataloader):\n",
    "#     loss = sgns(iword, owords)\n",
    "#     optim.zero_grad()\n",
    "#     loss.backward()\n",
    "#     optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "second-pollution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we create an one-hot encoding of all transactions ranked by chronological order\n",
    "#hot_encoding =  csr_matrix((np.ones(df.shape[0]),(df.index.values, df.index.values)), shape=(df.shape[0], df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "under-acrylic",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = '0x88e2efac3d2ef957fcd82ec201a506871ad06204'\n",
    "#np.unique(np.hstack((df.from_address.values, df['to_address'].values))).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decreased-season",
   "metadata": {},
   "source": [
    "## Creating a data  embedding (OLD)\n",
    "\n",
    "To be able to learn a classification of nodes on our graph, we need to transform the data on nodes to be able to express some of the information contained in graph form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-nursery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix of adjacency with line data relative to sent transactions only \n",
    "# %%time\n",
    "# from_c = CategoricalDtype(sorted(df.from_address.unique()), ordered=True)\n",
    "# to_c = CategoricalDtype(sorted(df.to_address.unique()), ordered=True)\n",
    "# \n",
    "# row = df.from_address.astype(from_c).cat.codes\n",
    "# col = df.to_address.astype(to_c).cat.codes\n",
    "# sparse = csr_matrix((df[\"value\"], (row, col)), \\\n",
    "#                            shape=(from_c.categories.size, to_c.categories.size))\n",
    "# print(sparse.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-block",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix of adjacency with line data relative to sent and received transactions \n",
    "%%time\n",
    "# first we add addresses that only received but not sent to first column \n",
    "to_add = df.loc[~df['to_address'].isin(df['from_address'])].copy()\n",
    "to_add = to_add.rename(columns={'to_address':'from_address','from_address':'to_address'})\n",
    "to_add['value'] = 0\n",
    "\n",
    "df = pd.concat((df,to_add))\n",
    "\n",
    "categories = CategoricalDtype(sorted(df.from_address.unique()), ordered=True) # will have all nodes! use it for all \n",
    "row = df.to_address.astype(categories).cat.codes\n",
    "col = df.from_address.astype(categories).cat.codes\n",
    "\n",
    "# sparse matrix for values sent \n",
    "sp = csr_matrix((df['value'],(row, col)), shape=(categories.categories.size, categories.categories.size)\n",
    "                \n",
    "# sparse matrix for values received \n",
    "sp2 = csr_matrix((-df['value'],(col, row)), shape=(categories.categories.size, categories.categories.size))\n",
    "                \n",
    "# our data \n",
    "X = scipy.sparse.hstack((sp,sp2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-argument",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gorgeous-livestock",
   "metadata": {},
   "source": [
    "##  Dimension Reduction   \n",
    "\n",
    "Our data has particularly high dimension. We use truncated SVD to reduce our data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-revelation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-support",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tsvd = TruncatedSVD(n_components=65, random_state=42)\n",
    "out = tsvd.fit_transform(X)\n",
    "print(f'our data has shape {out.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plain-criminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsvd_var_ratios = tsvd.explained_variance_ratio_\n",
    "print(tsvd_var_ratios.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "three-channels",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken on https://chrisalbon.com/machine_learning/feature_engineering/select_best_number_of_components_in_tsvd/\n",
    "def select_n_components(var_ratio, goal_var: float) -> int:\n",
    "    total_variance = 0.0\n",
    "    n_components = 0\n",
    "    for explained_variance in var_ratio:\n",
    "        total_variance += explained_variance\n",
    "        n_components += 1\n",
    "        if total_variance >= goal_var:\n",
    "            break\n",
    "    return n_components\n",
    "\n",
    "var_goal =  0.99\n",
    "print(f'to keep {var_goal*100}% of variance, one should keep {select_n_components(tsvd_var_ratios,var_goal)} components')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elect-machinery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Debugging example\n",
    "# a = pd.DataFrame({\"col\": [15, 32, 3, 8], \"col2\":[26,3,17,20], \"value\":[1,1,1,1]})\n",
    "# \n",
    "# # add this to the sparse matrix \n",
    "# add = a.loc[~a['col2'].isin(a['col'])].copy()\n",
    "# add = add.rename(columns={'col':'col2','col2':'col'})\n",
    "# #add['value'] = 0 # -to_add['value']\n",
    "# \n",
    "# a = pd.concat((a,add))\n",
    "# \n",
    "# categories = CategoricalDtype(sorted(a.col.unique()), ordered=True) # will have all nodes! use it for all \n",
    "# row = a.col.astype(categories).cat.codes\n",
    "# col = a.col2.astype(categories).cat.codes\n",
    "# sp = csr_matrix((a['value'],(row, col)), shape=(categories.categories.size, categories.categories.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-klein",
   "metadata": {},
   "source": [
    "## Handling time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immediate-carrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-garbage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['day'] = df['unix_block_timestamp']//(60*60*24)  # euclidean division to get the day number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-artwork",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # tests\n",
    "# df['unix_block_timestamp'].max()//(60*60*24)\n",
    "# datetime.utcfromtimestamp(df['unix_block_timestamp'].max())\n",
    "# datetime.utcfromtimestamp(df['unix_block_timestamp'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-pittsburgh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby(by='day').count().plot(y='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facial-thought",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  plt.subplots(figsize = (20,7))\n",
    "#  test = df.groupby(['day']).nunique()['from_address']\n",
    "#  test.hist(bins = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dynamic-event",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulated-mathematics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.subplots(figsize = (20,7))\n",
    "# df.groupby(by='day').count()['value'].hist(bins = 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
