{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "solid-township",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "brown-journalist",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import glob \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import os \n",
    "import sklearn\n",
    "import scipy.sparse\n",
    "from scipy.sparse import csr_matrix\n",
    "from pandas.api.types import CategoricalDtype\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "constant-crisis",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/julesbaudet/Documents/0. Cours/ENS/Deep Learning DIY/Projet final/ens_data\"\n",
    "# path = \"/Users/linusbleistein/Documents/Cours ENS/Cours math√©matiques/Deep learning 2020-2021/data_project\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "lesbian-eleven",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>from_address</th>\n",
       "      <th>to_address</th>\n",
       "      <th>value</th>\n",
       "      <th>unix_block_timestamp</th>\n",
       "      <th>send_is_id</th>\n",
       "      <th>receive_is_id</th>\n",
       "      <th>labels_send</th>\n",
       "      <th>labels_receive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2438955</td>\n",
       "      <td>0x88e2efac3d2ef957fcd82ec201a506871ad06204</td>\n",
       "      <td>0x67fa2c06c9c6d4332f330e14a66bdf1873ef3d2b</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1496084349</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2305151</td>\n",
       "      <td>0x88e2efac3d2ef957fcd82ec201a506871ad06204</td>\n",
       "      <td>0x67fa2c06c9c6d4332f330e14a66bdf1873ef3d2b</td>\n",
       "      <td>7999999.0</td>\n",
       "      <td>1496085435</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>539714</td>\n",
       "      <td>0x88e2efac3d2ef957fcd82ec201a506871ad06204</td>\n",
       "      <td>0x67fa2c06c9c6d4332f330e14a66bdf1873ef3d2b</td>\n",
       "      <td>12000000.0</td>\n",
       "      <td>1496085651</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>539777</td>\n",
       "      <td>0x88e2efac3d2ef957fcd82ec201a506871ad06204</td>\n",
       "      <td>0x67fa2c06c9c6d4332f330e14a66bdf1873ef3d2b</td>\n",
       "      <td>113650000.0</td>\n",
       "      <td>1496085802</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>270439</td>\n",
       "      <td>0x00954e1c8fcf1c5c274aa10b1260a94564f47b58</td>\n",
       "      <td>0x023656f850bbf662e71006b3891e797653503286</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1496241893</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                from_address  \\\n",
       "0     2438955  0x88e2efac3d2ef957fcd82ec201a506871ad06204   \n",
       "1     2305151  0x88e2efac3d2ef957fcd82ec201a506871ad06204   \n",
       "2      539714  0x88e2efac3d2ef957fcd82ec201a506871ad06204   \n",
       "3      539777  0x88e2efac3d2ef957fcd82ec201a506871ad06204   \n",
       "4      270439  0x00954e1c8fcf1c5c274aa10b1260a94564f47b58   \n",
       "\n",
       "                                   to_address        value  \\\n",
       "0  0x67fa2c06c9c6d4332f330e14a66bdf1873ef3d2b          1.0   \n",
       "1  0x67fa2c06c9c6d4332f330e14a66bdf1873ef3d2b    7999999.0   \n",
       "2  0x67fa2c06c9c6d4332f330e14a66bdf1873ef3d2b   12000000.0   \n",
       "3  0x67fa2c06c9c6d4332f330e14a66bdf1873ef3d2b  113650000.0   \n",
       "4  0x023656f850bbf662e71006b3891e797653503286         10.0   \n",
       "\n",
       "   unix_block_timestamp  send_is_id  receive_is_id  labels_send  \\\n",
       "0            1496084349           0              0          NaN   \n",
       "1            1496085435           0              0          NaN   \n",
       "2            1496085651           0              0          NaN   \n",
       "3            1496085802           0              0          NaN   \n",
       "4            1496241893           0              0          NaN   \n",
       "\n",
       "   labels_receive  \n",
       "0             NaN  \n",
       "1             NaN  \n",
       "2             NaN  \n",
       "3             NaN  \n",
       "4             NaN  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(path,\"clean_brave_data.csv\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "democratic-baker",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = 'Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "psychological-oregon",
   "metadata": {},
   "source": [
    "## Transaction History Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "affiliated-relation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the known exchange list \n",
    "exch_labels = pd.read_csv(os.path.join(path, \"exchanges_encoded.csv\"), \n",
    "                          delimiter=';', names  = ['address','label']).set_index('address')\n",
    "\n",
    "labels = exch_labels.to_dict()['label']\n",
    "\n",
    "labels2int = dict(zip(labels.values(),[i for i in range(len(labels))])) # keys = addresses, values = name of the exchange\n",
    "address2int = {k:labels2int[labels[k]] for k in labels.keys()}\n",
    "\n",
    "known_addresses = list(labels.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "extreme-acoustic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop transactions of addresses who only made 1 transaction \n",
    "a = (df.groupby('from_address').count() + df.groupby('to_address').count())['value']\n",
    "idx = a[a<3][~a[a<3].index.isin(known_addresses)].index\n",
    "df = df.drop(df.loc[df['from_address'].isin(idx)|df['from_address'].isin(idx)].index).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "weighted-equilibrium",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['address_id'] = df['from_address'] + df['from_address']\n",
    "np.savetxt('data/corpus.txt',df['address_id'].values, fmt = '%s', delimiter =' ', newline =' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "increased-sunset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read dataset...\n",
      "got vocab 28264, total_word_count 2172842\n",
      "gen negative sample table...\n",
      "done.\n",
      "gen sub sampling table...\n",
      "done.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/Documents/0. Cours/ENS/Deep Learning DIY/Projet final/DL_ens/word2vec/train.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mw2v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/trainset.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model_test.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0mw2v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/0. Cours/ENS/Deep Learning DIY/Projet final/DL_ens/word2vec/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     54\u001b[0m                       \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhalf_window_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhalf_window_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mbatch_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mapprox_pair\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mpos_u\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_samples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence_cursor\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence_len\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/0. Cours/ENS/Deep Learning DIY/Projet final/DL_ens/word2vec/data_handler.py\u001b[0m in \u001b[0;36mgen_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    161\u001b[0m                 \u001b[0mpos_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0mpos_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m                 \u001b[0mneg_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnegative_sampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpos_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mpos_pairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpos_pairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/0. Cours/ENS/Deep Learning DIY/Projet final/DL_ens/word2vec/data_handler.py\u001b[0m in \u001b[0;36mnegative_sampling\u001b[0;34m(self, pos1, pos2)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mnegs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnegs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg_sample_count\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0m_negs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg_sample_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg_sample_count\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnegs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mnegs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_negs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mpos1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mpos2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mprod\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mprod\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2998\u001b[0m     \"\"\"\n\u001b[1;32m   2999\u001b[0m     return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,\n\u001b[0;32m-> 3000\u001b[0;31m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0m\u001b[1;32m   3001\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_wrapreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     passkwargs = {k: v for k, v in kwargs.items()\n\u001b[0m\u001b[1;32m     72\u001b[0m                   if v is not np._NoValue}\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 9s, sys: 22.6 s, total: 1min 32s\n",
      "Wall time: 1min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%run word2vec/train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "desirable-radius",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum([len(v)!=42 for v in df['from_address'].values]) # check that all addresses have same format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "duplicate-chest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['transaction_id'] = df['from_address']+df['to_address']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "matched-salmon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['transaction_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "early-acrylic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.sort_values('unix_block_timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "directed-commons",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_size = df['transaction_id'].nunique()\n",
    "# word2vec = Word2Vec(vocab_size=vocab_size, embedding_size=300)\n",
    "# sgns = SGNS(embedding=word2vec, vocab_size=vocab_size, n_negs=20)\n",
    "# optim = Adam(sgns.parameters())\n",
    "# for batch, (iword, owords) in enumerate(dataloader):\n",
    "#     loss = sgns(iword, owords)\n",
    "#     optim.zero_grad()\n",
    "#     loss.backward()\n",
    "#     optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "corrected-filing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we create an one-hot encoding of all transactions ranked by chronological order\n",
    "hot_encoding =  csr_matrix((np.ones(df.shape[0]),(df.index.values, df.index.values)), shape=(df.shape[0], df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "returning-rapid",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = '0x88e2efac3d2ef957fcd82ec201a506871ad06204'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "generous-leonard",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.unique(np.hstack((df.from_address.values, df['to_address'].values))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "blessed-continent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we create a dictionnary address: [transaction nbrs] where the transaction nbrs involve the address\n",
    "all_addresses  = np.hstack((df.from_address.unique(),\n",
    "                            df.loc[~df['to_address'].isin(df['from_address'])].to_address.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "waiting-client",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_add = df.loc[~df['to_address'].isin(df['from_address'])].copy()\n",
    "to_add = to_add.rename(columns={'to_address':'from_address','from_address':'to_address'})\n",
    "to_add['value'] = 0\n",
    "df2 = pd.concat((df,to_add))\n",
    "\n",
    "categories = CategoricalDtype(sorted(df2.from_address.unique()), ordered=True) # will have all nodes! use it for all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "vanilla-router",
   "metadata": {},
   "outputs": [],
   "source": [
    "from_c = df.from_address.astype(categories).cat.codes # .unique().shape\n",
    "to_c = df.loc[df.from_address != df.to_address].to_address.astype(categories).cat.codes\n",
    "\n",
    "vocab = pd.DataFrame(np.hstack((from_c,to_c)), columns=['address'])\n",
    "vocab['transactions'] = np.hstack((from_c.index, to_c.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "legitimate-germany",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.6 s, sys: 182 ms, total: 17.8 s\n",
      "Wall time: 18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vocab = vocab.groupby('address')['transactions'].apply(list).reset_index(name='transactions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "horizontal-setting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>transactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[[30449, 34453, 956587, 1348259, 1713041, 1926...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[[485438, 1486175]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[[457529]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[[1063476, 1234990]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[[513642, 513654]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   address                                       transactions\n",
       "0        0  [[30449, 34453, 956587, 1348259, 1713041, 1926...\n",
       "1        1                                [[485438, 1486175]]\n",
       "2        2                                         [[457529]]\n",
       "3        3                               [[1063476, 1234990]]\n",
       "4        4                                 [[513642, 513654]]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ARE THEY IN ORDER? CHECK! \n",
    "vocab.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neither-favor",
   "metadata": {},
   "source": [
    "## Transaction stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decreased-season",
   "metadata": {},
   "source": [
    "## Creating a data  embedding (OLD)\n",
    "\n",
    "To be able to learn a classification of nodes on our graph, we need to transform the data on nodes to be able to express some of the information contained in graph form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-nursery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix of adjacency with line data relative to sent transactions only \n",
    "# %%time\n",
    "# from_c = CategoricalDtype(sorted(df.from_address.unique()), ordered=True)\n",
    "# to_c = CategoricalDtype(sorted(df.to_address.unique()), ordered=True)\n",
    "# \n",
    "# row = df.from_address.astype(from_c).cat.codes\n",
    "# col = df.to_address.astype(to_c).cat.codes\n",
    "# sparse = csr_matrix((df[\"value\"], (row, col)), \\\n",
    "#                            shape=(from_c.categories.size, to_c.categories.size))\n",
    "# print(sparse.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "successful-block",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-68-4069e6302457>, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-68-4069e6302457>\"\u001b[0;36m, line \u001b[0;32m18\u001b[0m\n\u001b[0;31m    sp2 = csr_matrix((-df['value'],(col, row)), shape=(categories.categories.size, categories.categories.size))\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# matrix of adjacency with line data relative to sent and received transactions \n",
    "%%time\n",
    "# first we add addresses that only received but not sent to first column \n",
    "to_add = df.loc[~df['to_address'].isin(df['from_address'])].copy()\n",
    "to_add = to_add.rename(columns={'to_address':'from_address','from_address':'to_address'})\n",
    "to_add['value'] = 0\n",
    "\n",
    "df = pd.concat((df,to_add))\n",
    "\n",
    "categories = CategoricalDtype(sorted(df.from_address.unique()), ordered=True) # will have all nodes! use it for all \n",
    "row = df.to_address.astype(categories).cat.codes\n",
    "col = df.from_address.astype(categories).cat.codes\n",
    "\n",
    "# sparse matrix for values sent \n",
    "sp = csr_matrix((df['value'],(row, col)), shape=(categories.categories.size, categories.categories.size)\n",
    "                \n",
    "# sparse matrix for values received \n",
    "sp2 = csr_matrix((-df['value'],(col, row)), shape=(categories.categories.size, categories.categories.size))\n",
    "                \n",
    "# our data \n",
    "X = scipy.sparse.hstack((sp,sp2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-argument",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gorgeous-livestock",
   "metadata": {},
   "source": [
    "##  Dimension Reduction   \n",
    "\n",
    "Our data has particularly high dimension. We use truncated SVD to reduce our data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-revelation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-support",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tsvd = TruncatedSVD(n_components=65, random_state=42)\n",
    "out = tsvd.fit_transform(X)\n",
    "print(f'our data has shape {out.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plain-criminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsvd_var_ratios = tsvd.explained_variance_ratio_\n",
    "print(tsvd_var_ratios.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "three-channels",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken on https://chrisalbon.com/machine_learning/feature_engineering/select_best_number_of_components_in_tsvd/\n",
    "def select_n_components(var_ratio, goal_var: float) -> int:\n",
    "    total_variance = 0.0\n",
    "    n_components = 0\n",
    "    for explained_variance in var_ratio:\n",
    "        total_variance += explained_variance\n",
    "        n_components += 1\n",
    "        if total_variance >= goal_var:\n",
    "            break\n",
    "    return n_components\n",
    "\n",
    "var_goal =  0.99\n",
    "print(f'to keep {var_goal*100}% of variance, one should keep {select_n_components(tsvd_var_ratios,var_goal)} components')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pharmaceutical-brush",
   "metadata": {},
   "source": [
    "##  Adding the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-oakland",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.vectorize(address2int.get)(np.array(categories.categories))\n",
    "labels = np.nan_to_num(labels.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "returning-contamination",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-episode",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(out)\n",
    "# data['label'] = np.isin(np.array(sorted(df.from_address.unique())),known_addresses).astype(int)\n",
    "data['label'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blessed-source",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(os.path.join(path,\"processed_data.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "third-brisbane",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yellow-capitol",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elect-machinery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Debugging example\n",
    "# a = pd.DataFrame({\"col\": [15, 32, 3, 8], \"col2\":[26,3,17,20], \"value\":[1,1,1,1]})\n",
    "# \n",
    "# # add this to the sparse matrix \n",
    "# add = a.loc[~a['col2'].isin(a['col'])].copy()\n",
    "# add = add.rename(columns={'col':'col2','col2':'col'})\n",
    "# #add['value'] = 0 # -to_add['value']\n",
    "# \n",
    "# a = pd.concat((a,add))\n",
    "# \n",
    "# categories = CategoricalDtype(sorted(a.col.unique()), ordered=True) # will have all nodes! use it for all \n",
    "# row = a.col.astype(categories).cat.codes\n",
    "# col = a.col2.astype(categories).cat.codes\n",
    "# sp = csr_matrix((a['value'],(row, col)), shape=(categories.categories.size, categories.categories.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungry-circuit",
   "metadata": {},
   "source": [
    "## Handling time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "compact-notion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "small-sydney",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['day'] = df['unix_block_timestamp']//(60*60*24)  # euclidean division to get the day number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "conscious-spotlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # tests\n",
    "# df['unix_block_timestamp'].max()//(60*60*24)\n",
    "# datetime.utcfromtimestamp(df['unix_block_timestamp'].max())\n",
    "# datetime.utcfromtimestamp(df['unix_block_timestamp'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "purple-price",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby(by='day').count().plot(y='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "through-banking",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  plt.subplots(figsize = (20,7))\n",
    "#  test = df.groupby(['day']).nunique()['from_address']\n",
    "#  test.hist(bins = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "renewable-reliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "substantial-gambling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.subplots(figsize = (20,7))\n",
    "# df.groupby(by='day').count()['value'].hist(bins = 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
